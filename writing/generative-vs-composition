You asked whether generative midi compositions were instruments, and whether they have agency.

Not quite what I said :)

I asked whether click-to-play generative compositions (nothing about MIDI here) were beyond the bounds of this project. I am getting at the degree of interactivity for code instruments/objects at any step of the process. Same reason I brought up the thought experiment of including autonomous agents (which I would advise against, as this would complexift the experiment, I think.)
Ah! Well, I hadn’t thought of that. As long as the code in the click-to-play generative composition can be edited during each subsequent phases I think it would be fine. However, this then may pose a challenge for and group-based performance phase(s) within the piece… I suppose a patch which begins as a single-click-to-play generative composition in phase 1 may end up as a gesture controllable instrument by phase 5. This invites questions around what lengths the co-designers/co-composers may take to constrain structural changes to their work in subsequent phases. I’m not sure if I want to design the rules for the co-designers/co-composers with this in mind, or if it would be more appropriate to use this question to inform analysis at a later stage (i.e. could we compare the degree to which a system’s parameters are exposed to manual control, in a given phase, against the amount of code churn between that phase and the next; or that phase and the last phase. Or plot a patch’s controlability over its entire history, and look for correlations between this and how much the patch was edited by co-designers.  